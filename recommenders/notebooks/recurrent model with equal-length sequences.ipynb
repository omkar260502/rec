{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:48:56.510340Z",
     "start_time": "2019-07-14T12:48:56.499579Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:01.915966Z",
     "start_time": "2019-07-14T12:48:56.704479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import preprocess_utils.session2vec as sess2vec\n",
    "import utils.sparsedf as sparsedf\n",
    "from utils.df import MinMaxScaler\n",
    "from utils.dataset import SequenceDatasetForClassification, SequenceDatasetForRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:02.431535Z",
     "start_time": "2019-07-14T12:49:01.919006Z"
    }
   },
   "outputs": [],
   "source": [
    "from recommenders.recommender_base import RecommenderBase\n",
    "from recommenders.recurrent.RNNClassificationRecommender import RNNClassificationRecommender\n",
    "\n",
    "from numpy.linalg import norm as L2Norm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, GRU, Embedding\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:02.438885Z",
     "start_time": "2019-07-14T12:49:02.433681Z"
    }
   },
   "outputs": [],
   "source": [
    "mode = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:07.985413Z",
     "start_time": "2019-07-14T12:49:07.976824Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SequenceDatasetForClassification(f'dataset/preprocessed/cluster_recurrent/{mode}/dataset_classification_p6')\n",
    "#dataset = SequenceDatasetForClassification(f'dataset/preprocessed/cluster_up_to_len6/{mode}/dataset_classification')\n",
    "#dataset = SequenceDatasetForClassification(f'dataset/preprocessed/cluster_over_len6/{mode}/dataset_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T21:56:35.887408Z",
     "start_time": "2019-07-12T21:56:35.560647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: (37664, 25)\n",
      "{0: 0.10620796616143814, 1: 0.3912126720332381, 2: 0.5512477131357483, 3: 0.7377864838393732, 4: 0.847334083239595, 5: 1.0297744360902255, 6: 1.223850528025995, 7: 1.3847058823529412, 8: 1.5420266120777892, 9: 1.735668202764977, 10: 1.799952210274791, 11: 1.9290140845070423, 12: 2.1993576642335766, 13: 2.5797260273972604, 14: 2.7145225225225227, 15: 3.055902636916836, 16: 3.068350305498982, 17: 3.6042105263157893, 18: 3.275130434782609, 19: 3.8530946291560104, 20: 3.954225721784777, 21: 4.184888888888889, 22: 4.593170731707317, 23: 4.782730158730159, 24: 4.082818428184281}\n"
     ]
    }
   ],
   "source": [
    "weights = dataset.get_class_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:09.946074Z",
     "start_time": "2019-07-14T12:49:09.070222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 6, 64)             44736     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1625      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 75,289\n",
      "Trainable params: 75,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = RecurrentRecommender(dataset, loss='categorical_crossentropy', cell_type='gru', num_units=50, num_layers=2)\n",
    "model = RNNClassificationRecommender(dataset, input_shape=(dataset.rows_per_sample, 168),\n",
    "                                     cell_type='gru',\n",
    "                                     num_recurrent_units=64,\n",
    "                                     num_recurrent_layers=2, num_dense_layers=2,\n",
    "                                     optimizer=keras.optimizers.Adam(lr=1e-2),\n",
    "                                     class_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset.load_Xtrain(), dataset.load_Ytrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37664, 6, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [7.40740741e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.16202416e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00],\n",
       "       [7.40740741e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.03358697e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [7.40740741e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 3.78378378e-01, 4.48648649e-01,\n",
       "        8.10810811e-01, 7.72972973e-01, 4.64864865e-01, 4.00000000e-01,\n",
       "        4.21621622e-01, 5.18918919e-01, 2.97297297e-01, 3.89189189e-01,\n",
       "        6.32432432e-01, 4.54054054e-01, 4.97297297e-01, 3.02702703e-01,\n",
       "        5.83783784e-01, 7.62162162e-01, 4.86486486e-01, 6.59459459e-01,\n",
       "        4.21621622e-01, 7.02702703e-01, 4.16216216e-01, 4.59459459e-01,\n",
       "        1.00000000e+00, 2.59459459e-01, 4.10810811e-01, 1.00559783e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [7.40740741e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 3.78378378e-01, 4.48648649e-01,\n",
       "        8.10810811e-01, 7.72972973e-01, 4.64864865e-01, 4.00000000e-01,\n",
       "        4.21621622e-01, 5.18918919e-01, 2.97297297e-01, 3.89189189e-01,\n",
       "        6.32432432e-01, 4.54054054e-01, 4.97297297e-01, 3.02702703e-01,\n",
       "        5.83783784e-01, 7.62162162e-01, 4.86486486e-01, 6.59459459e-01,\n",
       "        4.21621622e-01, 7.02702703e-01, 4.16216216e-01, 4.59459459e-01,\n",
       "        1.00000000e+00, 2.59459459e-01, 4.10810811e-01, 6.03358697e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [7.40740741e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 4.71698113e-01, 3.89937107e-01,\n",
       "        7.10691824e-01, 5.72327044e-01, 6.66666667e-01, 7.23270440e-01,\n",
       "        4.71698113e-01, 4.27672956e-01, 5.09433962e-01, 5.40880503e-01,\n",
       "        2.26415094e-01, 4.15094340e-01, 5.40880503e-01, 1.00000000e+00,\n",
       "        9.11949686e-01, 7.35849057e-01, 4.33962264e-01, 6.60377358e-01,\n",
       "        4.08805031e-01, 5.40880503e-01, 5.15723270e-01, 5.22012579e-01,\n",
       "        4.52830189e-01, 6.66666667e-01, 5.91194969e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T21:58:14.440815Z",
     "start_time": "2019-07-12T21:57:08.212129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (37664, 6, 168)\n",
      "Train on 32014 samples, validate on 5650 samples\n",
      "Epoch 1/3\n",
      "32014/32014 [==============================] - 26s 801us/step - loss: 3.5650 - acc: 0.3919 - mrr: 0.5070 - val_loss: 2.0151 - val_acc: 0.4846 - val_mrr: 0.6023\n",
      "Epoch 2/3\n",
      "32014/32014 [==============================] - 19s 604us/step - loss: 3.4691 - acc: 0.4238 - mrr: 0.5350 - val_loss: 1.9940 - val_acc: 0.5009 - val_mrr: 0.6115\n",
      "Epoch 3/3\n",
      "32014/32014 [==============================] - 19s 595us/step - loss: 3.4104 - acc: 0.4345 - mrr: 0.5440 - val_loss: 2.0032 - val_acc: 0.4988 - val_mrr: 0.6108\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, epochs=10, validation_split=0.1)\n",
    "model.fit(epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:29.655578Z",
     "start_time": "2019-07-14T12:49:28.208416Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.model.save('gru_permutation_importance.h5')\n",
    "model.load('gru_permutation_importance.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T21:55:41.176595Z",
     "start_time": "2019-07-12T21:55:40.886943Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load('gru_primo_tentativo_dopo_preprocessing.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 12, 64)            45120     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1625      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 75,673\n",
      "Trainable params: 75,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNClassificationRecommender(dataset, cell_type='gru', num_recurrent_units=64, num_recurrent_layers=2,\n",
    "                                     num_dense_layers=2, input_shape=(dataset.rows_per_sample, 170),\n",
    "                                     class_weights=[])\n",
    "model.load('saved_models/rnn_GRU_2layers_64units_2dense_class_066392.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5b11eb2125ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gru.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load('gru.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153130\n",
      "[54066 54071 54108 54184 54211 54343 54397 54606 54609 54906]\n"
     ]
    }
   ],
   "source": [
    "#X_test_df = pd.read_csv(f'dataset/preprocessed/cluster_recurrent/{mode}/X_test.csv').set_index('orig_index')\n",
    "#X_test_df = scale_dataframe(X_test_df, ['impression_price'])\n",
    "\n",
    "target_indices = data.target_indices(mode, 'cluster_recurrent')\n",
    "#target_indices = data.target_indices(mode, 'cluster_recurrent_up_to_len6')\n",
    "#target_indices = data.target_indices(mode)\n",
    "#X_test_df.head(3)\n",
    "print(len(target_indices))\n",
    "print(target_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded!\n",
      "X_test: (153130, 12, 167)\n",
      "caching df_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "  0%|          | 1/153130 [00:00<5:14:51,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153130/153130 [00:56<00:00, 2711.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction created !!!\n",
      "Loading full train_df, it will take a while..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 153130/153130 [00:00<00:00, 887880.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MRR (hoping for a 0.99)\n",
      "MRR: 0.6627973069423838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recomendations = model.recommend_batch(target_indices)\n",
    "if mode != 'full':\n",
    "    model.compute_MRR(recomendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtest, indices = dataset.load_Xtest()\n",
    "\n",
    "# build y_true\n",
    "def get_y_true(clickout_indices, mode):\n",
    "    df = data.full_df().loc[clickout_indices]\n",
    "    \n",
    "    def add_label(row):\n",
    "        impress = list(map(int, row['impressions'].split('|')))\n",
    "        ref = row['reference']\n",
    "        #if pd.isnull(ref):\n",
    "        #    return np.NaN\n",
    "\n",
    "        if ref in impress:\n",
    "            return impress.index(ref)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    df = df.astype({'reference':'int'})\n",
    "    df['label'] = df.progress_apply(add_label, axis=1)\n",
    "    return df['label']\n",
    " \n",
    "yclasses = get_y_true(indices, mode)\n",
    "\n",
    "#y_true = np.zeros((len(yclasses), 25))\n",
    "#y_true[np.arange(y_true.shape[0]),yclasses] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.model.predict_classes(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## rnn_GRU_2layers_64units_2dense_class_065193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.69     58083\n",
      "           1       0.55      0.31      0.40     15639\n",
      "           2       0.56      0.32      0.41     10693\n",
      "           3       0.51      0.33      0.40      8501\n",
      "           4       0.53      0.31      0.39      7315\n",
      "           5       0.54      0.32      0.40      5750\n",
      "           6       0.51      0.31      0.39      4917\n",
      "           7       0.53      0.32      0.40      4393\n",
      "           8       0.55      0.32      0.41      3947\n",
      "           9       0.53      0.32      0.40      3655\n",
      "          10       0.55      0.30      0.39      3275\n",
      "          11       0.53      0.31      0.39      2810\n",
      "          12       0.55      0.31      0.40      2741\n",
      "          13       0.57      0.30      0.40      2480\n",
      "          14       0.56      0.32      0.41      2179\n",
      "          15       0.58      0.31      0.40      2125\n",
      "          16       0.59      0.33      0.42      2005\n",
      "          17       0.60      0.31      0.41      1858\n",
      "          18       0.58      0.31      0.40      1681\n",
      "          19       0.62      0.30      0.41      1588\n",
      "          20       0.61      0.29      0.39      1545\n",
      "          21       0.61      0.32      0.42      1380\n",
      "          22       0.69      0.33      0.44      1409\n",
      "          23       0.70      0.30      0.43      1451\n",
      "          24       0.69      0.32      0.43      1710\n",
      "\n",
      "   micro avg       0.55      0.55      0.55    153130\n",
      "   macro avg       0.58      0.34      0.42    153130\n",
      "weighted avg       0.55      0.55      0.51    153130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yclasses, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Features:\n",
    "ReferencePositionInLastClickoutImpressions,\n",
    "\n",
    "GlobalClickoutPopularity,\n",
    "\n",
    "ReferencePriceInLastClickout,\n",
    "\n",
    "ReferencePricePositionInLastClickout,\n",
    "\n",
    "SessionsImpressionsCount,\n",
    "\n",
    "ClickoutVectorPrices,\n",
    "\n",
    "InteractionDuration,\n",
    "\n",
    "2x64 gru - 2 dense\n",
    "#### 0.64470\n",
    "\n",
    "### Features:\n",
    "ReferencePositionInLastClickoutImpressions,\n",
    "\n",
    "GlobalClickoutPopularity,\n",
    "\n",
    "ReferencePriceInLastClickout,\n",
    "\n",
    "SessionsImpressionsCount\n",
    "\n",
    "2x64 gru - 2 dense\n",
    "#### 0.64273\n",
    "\n",
    "\n",
    "### Features\n",
    "ReferencePositionInLastClickoutImpressions,\n",
    "\n",
    "ReferencePriceInLastClickout,\n",
    "\n",
    "ClickoutVectorPrices,\n",
    "#### 0.62387\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Cluster len<=6\n",
    "\n",
    "With 1 time distributed: 0.625722\n",
    "\n",
    "Naive: 0.625908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Export sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import out\n",
    "\n",
    "def create_sub(model, sub_suffix=''):\n",
    "    mode = 'full'\n",
    "    target_indices = data.target_indices(mode, 'cluster_recurrent')\n",
    "    print('Recommending...')\n",
    "    recomendations = model.recommend_batch(target_indices)\n",
    "    out.create_sub(recomendations, submission_name=f'{model.name}_{sub_suffix}')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (253573, 12, 118)\n",
      "caching df_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/Documents/Repository/recsys2019/recommenders/recurrent/RNNClassificationRecommender.py:50: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  predictions = pred_df.loc[target_indices]\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "  0%|          | 1/253573 [00:00<7:15:37,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253573/253573 [01:32<00:00, 2741.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction created !!!\n",
      "Exporting the sub to submissions/rnn_GRU_2layers_64units_2dense_wgt_class__09-56-34.csv...\n",
      "\n",
      "submission created in submissions folder in 00m 04s\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "create_sub(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the sub to submissions/rnn_GRU_2layers_64units_2dense_wgt_class_066279_18-35-41.csv...\n",
      "\n",
      "submission created in submissions folder in 00m 04s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submissions/rnn_GRU_2layers_64units_2dense_wgt_class_066279_18-35-41.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import out\n",
    "out.create_sub(recomendations, submission_name=f'{model.name}_066279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "xtest, indices = dataset.load_Xtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (153135, 6, 68)\n",
      "caching df_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "605it [00:00, 1896.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153135it [00:33, 4583.94it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = model.get_scores_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_GRU_2layers_64units_2dense_class'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('rnn_GRU_2layers_64units_2dense_wgt_class_055780_balanced', np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:42.853171Z",
     "start_time": "2019-07-14T12:49:42.428421Z"
    }
   },
   "outputs": [],
   "source": [
    "from eli5.sklearn.permutation_importance import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:45.190060Z",
     "start_time": "2019-07-14T12:49:45.175431Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_fn(model, X, y):\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    target_indices = data.target_indices(model.mode, 'cluster_recurrent')\n",
    "    \n",
    "    _, indices = self.dataset.load_Xtest()\n",
    "        \n",
    "    # predict the references\n",
    "    predictions = self.model.predict(X)\n",
    "\n",
    "    # take only the target predictions\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    pred_df['orig_index'] = indices\n",
    "    pred_df = pred_df.set_index('orig_index')\n",
    "    predictions = pred_df.loc[target_indices]\n",
    "    del pred_df\n",
    "\n",
    "    assert len(predictions) == len(target_indices)\n",
    "\n",
    "    full_df = data.full_df()\n",
    "\n",
    "    result_predictions = []\n",
    "    for index in tqdm(target_indices):\n",
    "        # get the impressions of the clickout to predict\n",
    "        impr = list(map(int, full_df.loc[index]['impressions'].split('|')))\n",
    "        # build a list of (impression, score)\n",
    "        prediction_impressions_distances = [ (impr[j], predictions.at[index,j]) for j in range(len(impr)) ]\n",
    "        # order the list based on scores (greater is better)\n",
    "        prediction_impressions_distances.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        # get only the impressions ids\n",
    "        ordered_impressions = list(map(lambda x: x[0], prediction_impressions_distances))\n",
    "        # append the couple (index, reranked impressions)\n",
    "        result_predictions.append( (index, ordered_impressions) )\n",
    "\n",
    "    if model.mode == 'full':\n",
    "        print('Invalid mode (full)!')\n",
    "        return None\n",
    "    \n",
    "    return model.compute_MRR(result_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:45.548790Z",
     "start_time": "2019-07-14T12:49:45.545318Z"
    }
   },
   "outputs": [],
   "source": [
    "perm_importance = PermutationImportance(model, score_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:49:47.387961Z",
     "start_time": "2019-07-14T12:49:46.073937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: (9246, 6, 168)\n",
      "(9246, 6, 168)\n",
      "(9246, 1)\n"
     ]
    }
   ],
   "source": [
    "x, _ = dataset.load_Xtest()\n",
    "print(x.shape)\n",
    "y = np.zeros((x.shape[0],1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T12:50:08.863001Z",
     "start_time": "2019-07-14T12:50:08.844385Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bede79232d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperm_importance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.6/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prefit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "perm_importance.fit(np.array([[None, None]]), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
