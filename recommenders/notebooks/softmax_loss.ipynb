{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import preprocess_utils.session2vec as sess2vec\n",
    "import utils.sparsedf as sparsedf\n",
    "from utils.df import MinMaxScaler\n",
    "from utils.dataset import SequenceDatasetForClassification, SequenceDatasetForRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender_base import RecommenderBase\n",
    "from recommenders.recurrent.RNNClassificationRecommender import RNNClassificationRecommender\n",
    "\n",
    "from numpy.linalg import norm as L2Norm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, GRU, Embedding, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDatasetForClassification(f'dataset/preprocessed/cluster_recurrent/{mode}/dataset_classification_p6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (37664, 6, 118)\n",
      "Y_train: (37664, 25)\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset.load_Xtrain(), dataset.load_Ytrain()\n",
    "x, y = shuffle(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def softmax_loss(y_true, y_pred):\n",
    "    y_pred = K.print_tensor(y_pred, message='pred = ')\n",
    "\n",
    "    softmax = K.softmax(y_pred)\n",
    "    softmax = K.print_tensor(softmax, message='softmax = ')\n",
    "\n",
    "    log_soft = K.log(softmax)\n",
    "    log_soft = K.print_tensor(log_soft, message='log softmax = ')\n",
    "\n",
    "    #batchd = K.batch_dot(y_true, log_soft, axes=1)\n",
    "    batchd = y_true * log_soft\n",
    "    batchd = K.print_tensor(batchd, message='batch dot = ')\n",
    "\n",
    "    return -K.sum(batchd)\n",
    "\n",
    "def soft_loss2(y_true, y_pred):\n",
    "    preds_softmax = tf.nn.softmax(y_pred)\n",
    "    step1 = y_true * tf.log(preds_softmax)\n",
    "    return -tf.reduce_sum(step1, reduction_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(y_true, y_pred):\n",
    "    y_true = y_true\n",
    "    y_pred = y_pred\n",
    "    mrr = 0\n",
    "    current_percentage = 0\n",
    "    for i in range(1, 26, 1):\n",
    "        if i == 1:\n",
    "            mrr = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "            current_percentage = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "        else:\n",
    "            t = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "            mrr += (t - current_percentage) * (1 / i)\n",
    "            current_percentage = t\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 6, 64)             35136     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 32)                9312      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                825       \n",
      "=================================================================\n",
      "Total params: 46,329\n",
      "Trainable params: 46,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = Sequential()\n",
    "#m.add( TimeDistributed(Dense(64), input_shape=(6,68)) )\n",
    "m.add( GRU(64, input_shape=(6,118), recurrent_dropout=0.2, dropout=0.2, return_sequences=True) )\n",
    "m.add( GRU(32, recurrent_dropout=0.2, dropout=0.2, return_sequences=False) )\n",
    "m.add( Dense(32, activation='relu') )\n",
    "#m.add( Dropout(0.2) )\n",
    "m.add( Dense(25, activation='softmax') )\n",
    "#m.add( Dropout(0.1) )\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=1e-1)\n",
    "#m.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "m.compile(adam, loss='cosine_proximity', metrics=['accuracy', mrr])\n",
    "#m.compile(adam, loss=soft_loss2, metrics=['accuracy', mrr])\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30131 samples, validate on 7533 samples\n",
      "Epoch 1/3\n",
      "30131/30131 [==============================] - 26s 868us/step - loss: -0.3776 - acc: 0.3776 - mrr: 0.4688 - val_loss: -0.3729 - val_acc: 0.3729 - val_mrr: 0.4636\n",
      "Epoch 2/3\n",
      "30131/30131 [==============================] - 25s 836us/step - loss: -0.3776 - acc: 0.3776 - mrr: 0.4688 - val_loss: -0.3729 - val_acc: 0.3729 - val_mrr: 0.4636\n",
      "Epoch 3/3\n",
      " 9472/30131 [========>.....................] - ETA: 17s - loss: -0.3785 - acc: 0.3785 - mrr: 0.4696"
     ]
    }
   ],
   "source": [
    "m.fit(x=x, y=y, epochs=3, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54066, 54071, 54108, 54184, 54211, 54343, 54397, 54606, 54609,\n",
       "       54692])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_indices = data.target_indices(mode)\n",
    "target_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_batch(m, dataset, target_indices):\n",
    "    X, indices = dataset.load_Xtest()\n",
    "\n",
    "    # predict the references\n",
    "    predictions = m.predict(X)\n",
    "\n",
    "    # take only the last index for each session (target row) and flatten\n",
    "    #predictions = predictions.reshape((-1, predictions.shape[-1]))\n",
    "    #indices = indices[:,-1].flatten()\n",
    "\n",
    "    # take only the target predictions\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    pred_df['orig_index'] = indices\n",
    "    pred_df = pred_df.set_index('orig_index')\n",
    "    predictions = pred_df.loc[target_indices]\n",
    "    del pred_df\n",
    "\n",
    "    assert len(predictions) == len(target_indices)\n",
    "\n",
    "    full_df = data.full_df()\n",
    "\n",
    "    result_predictions = []\n",
    "    for index in tqdm(target_indices):\n",
    "        # get the impressions of the clickout to predict\n",
    "        impr = list(map(int, full_df.loc[index]['impressions'].split('|')))\n",
    "        # build a list of (impression, score)\n",
    "        prediction_impressions_distances = [ (impr[j], predictions.at[index,j]) for j in range(len(impr)) ]\n",
    "        # order the list based on scores (greater is better)\n",
    "        prediction_impressions_distances.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        # get only the impressions ids\n",
    "        ordered_impressions = list(map(lambda x: x[0], prediction_impressions_distances))\n",
    "        # append the couple (index, reranked impressions)\n",
    "        result_predictions.append( (index, ordered_impressions) )\n",
    "\n",
    "    print('prediction created !!!')\n",
    "\n",
    "    return result_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MRR(mode, predictions):\n",
    "    \"\"\"\n",
    "    compute the MRR mean reciprocal rank of some predictions\n",
    "    it uses the mode parameter to know which handle to retrieve to compute the score\n",
    "\n",
    "    :param mode: 'local' or 'small' say which train has been used\n",
    "    :param predictions: session_id, ordered impressions_list\n",
    "    :param verboose: if True print the MRR\n",
    "    :return: MRR of the given predictions\n",
    "    \"\"\"\n",
    "    assert (mode == 'local' or mode == 'small')\n",
    "\n",
    "    train_df = data.train_df('full')   #data.train_df(\"full\", cluster=self.cluster)\n",
    "\n",
    "    target_indices, recs = zip(*predictions)\n",
    "    target_indices = list(target_indices)\n",
    "    correct_clickouts = train_df.loc[target_indices].reference.values\n",
    "    len_rec = len(recs)\n",
    "\n",
    "    RR = 0\n",
    "    print(\"Calculating MRR (hoping for a 0.99)\")\n",
    "    for i in tqdm(range(len_rec)):\n",
    "        correct_clickout = int(correct_clickouts[i])\n",
    "        if correct_clickout in predictions[i][1]:\n",
    "            rank_pos = recs[i].index(correct_clickout) + 1\n",
    "            if rank_pos <= 25:\n",
    "                RR += 1 / rank_pos\n",
    "\n",
    "    MRR = RR / len_rec\n",
    "    print(f'MRR: {MRR}')\n",
    "\n",
    "    return MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545c5d6373734e39a5ba125e3b432c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction created !!!\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_batch(m, dataset, target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MRR (hoping for a 0.99)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053c2fc338144227bb2e4589c014a704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.5099219530770764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5099219530770764"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_MRR(mode, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
