{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import dump_svmlight_file \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features.actions_involving_impression_session import ActionsInvolvingImpressionSession\n",
    "from extract_features.mean_price_clickout import MeanPriceClickout\n",
    "from extract_features.label import ImpressionLabel\n",
    "from extract_features.impression_position_session import ImpressionPositionSession\n",
    "from extract_features.session_length import SessionLength\n",
    "from extract_features.session_device import SessionDevice\n",
    "from extract_features.session_filters_active_when_clickout import SessionFilterActiveWhenClickout\n",
    "from extract_features.session_sort_order_when_clickout import SessionSortOrderWhenClickout\n",
    "from extract_features.impression_price_info_session import ImpressionPriceInfoSession\n",
    "from extract_features.times_user_interacted_with_impression import TimesUserInteractedWithImpression\n",
    "from extract_features.timing_from_last_interaction_impression import TimingFromLastInteractionImpression\n",
    "from extract_features.last_action_involving_impression import LastInteractionInvolvingImpression\n",
    "from extract_features.session_actions_num_ref_diff_from_impressions import SessionActionNumRefDiffFromImpressions\n",
    "from extract_features.impression_features import ImpressionFeature\n",
    "from extract_features.item_popularity_session import ItemPopularitySession\n",
    "\n",
    "from extract_features.average_cheap_price_position_clickout import AvgPriceAndPricePosition\n",
    "from extract_features.average_impression_pos_interacted import ImpressionPositionInteracted\n",
    "from extract_features.frenzy_factor_consecutive_steps import FrenzyFactorSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_target(df, tgt_usersession):\n",
    "    if tuple(df.head(1)[['user_id', 'session_id']].values[0]) in tgt_usersession:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reinsert_clickout(df):\n",
    "    # take the row of the missing clickout\n",
    "    clickout_rows_df = df[(df['action_type'] == 'clickout item') & df['reference'].isnull()]\n",
    "    # check if it exsists\n",
    "    if len(clickout_rows_df)>0:\n",
    "        # retrieve from the full_df the clickout\n",
    "        missing_click = data.full_df().loc[clickout_rows_df.index[0]]['reference']\n",
    "        # reinsert the clickout on the df\n",
    "        df.at[clickout_rows_df.index[0], 'reference']= missing_click\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'small'\n",
    "cluster = 'no_cluster'\n",
    "features_array = {\n",
    "        'item_id': [ImpressionLabel, ImpressionPriceInfoSession, LastInteractionInvolvingImpression,\n",
    "                    TimingFromLastInteractionImpression, ImpressionPositionSession,\n",
    "                   TimesUserInteractedWithImpression],\n",
    "        'session': [MeanPriceClickout, SessionLength, SessionDevice, \n",
    "                    ImpressionPositionInteracted, AvgPriceAndPricePosition]\n",
    "    }\n",
    "#, , FrenzyFactorSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RETRIEVE THE FEATURES\n",
    "\"\"\"\n",
    "################################################\n",
    "\n",
    "# retrieve the impression feture df\n",
    "#impr_feature_df = ImpressionFeature(mode=mode, cluster=cluster).read_feature(one_hot=True)\n",
    "\n",
    "# list of pandas dataframe each element represent a feature\n",
    "pandas_dataframe_features_session_list = []\n",
    "for f in features_array['session']:\n",
    "    pandas_dataframe_features_session_list.append(f(mode=mode, cluster=cluster).read_feature(one_hot=True))\n",
    "\n",
    "# merge all the dataframes\n",
    "df_merged_session = reduce(lambda left, right: pd.merge(left, right, on=['user_id', 'session_id'],\n",
    "                                                how='inner'), pandas_dataframe_features_session_list)\n",
    "\n",
    "pandas_dataframe_features_item_list = []\n",
    "for f in features_array['item_id']:\n",
    "    pandas_dataframe_features_item_list.append(f(mode=mode, cluster=cluster).read_feature(one_hot=True))\n",
    "\n",
    "# merge all the dataframes\n",
    "df_merged_item = reduce(lambda left, right: pd.merge(left, right, on=['user_id', 'session_id', 'item_id'],\n",
    "                                                        how='inner'), pandas_dataframe_features_item_list)\n",
    "\n",
    "df_merged = pd.merge(df_merged_item, df_merged_session, on=['user_id', 'session_id'])\n",
    "\n",
    "# merge also the impression feature\n",
    "#df_merged = pd.merge(df_merged, impr_feature_df)\n",
    "\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the target indeces of the mode\n",
    "target_indeces = data.target_indices(mode, cluster)\n",
    "print(f'number of tgt index: {len(target_indeces)}')\n",
    "\n",
    "# load the full df\n",
    "full_df = data.full_df()\n",
    "\n",
    "# dict that has as keys the couples (user_id, session_id) that are target\n",
    "tgt_usersession = {}\n",
    "for index in target_indeces:\n",
    "    tgt_usersession[tuple(full_df.iloc[index][['user_id', 'session_id']].values)] = index\n",
    "\n",
    "is_target_ = df_merged.groupby(['user_id', 'session_id']).progress_apply(is_target, tgt_usersession=tgt_usersession)\n",
    "df_merged = pd.merge(df_merged, is_target_.reset_index(), on=['user_id', 'session_id'])\n",
    "\n",
    "test_df = df_merged[df_merged[0]==True]\n",
    "train_df = df_merged[df_merged[0]==False]\n",
    "\n",
    "del df_merged\n",
    "\n",
    "train_df.drop(columns=[0], inplace=True)\n",
    "test_df.drop(columns=[0], inplace=True)\n",
    "\n",
    "del full_df\n",
    "\n",
    "# retrieve the target indeces in the right order\n",
    "couples_dict = {}\n",
    "couples_arr = test_df[['user_id', 'session_id']].values\n",
    "for c in couples_arr:\n",
    "    if tuple(c) not in couples_dict:\n",
    "        couples_dict[tuple(c)] = 1\n",
    "\n",
    "target_us_reordered = list(couples_dict.keys())\n",
    "\n",
    "target_indeces_reordered = []\n",
    "for k in target_us_reordered:\n",
    "    target_indeces_reordered.append(tgt_usersession[k])\n",
    "\n",
    "print(f'number of tgt index: {len(target_indeces_reordered)}')\n",
    "target_indeces_reordered = np.array(target_indeces_reordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE DATA FOR TRAIN\n",
    "\n",
    "\"\"\"\n",
    "# associate to each session a QID\n",
    "qid = []\n",
    "\n",
    "count = 0\n",
    "actual_sid = 'culo'\n",
    "session_ids = train_df['session_id'].values\n",
    "for sid in session_ids:\n",
    "    if sid != actual_sid:\n",
    "        actual_sid = sid\n",
    "        count+=1\n",
    "    qid.append(count)\n",
    "np_qid_train = np.array(qid)\n",
    "\n",
    "\n",
    "\n",
    "# the 5 column is the label\n",
    "X, Y = train_df.iloc[:, 4:], train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "# normalize the values\n",
    "X_norm = scaler.fit_transform(X)\n",
    "Y_norm = Y.values\n",
    "\n",
    "X_train, X_val, Y_train, Y_val, qid_train, qid_val = \\\n",
    "train_test_split(X_norm, Y_norm, np_qid_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "dump_svmlight_file(X_train, Y_train, './train.txt', query_id=qid_train, zero_based=False)\n",
    "dump_svmlight_file(X_val, Y_val, './vali.txt', query_id=qid_val, zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(test_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE DATA FOR TEST\n",
    "\n",
    "\"\"\"\n",
    "# do it also fot the test data\n",
    "qid_test = []\n",
    "count = 0\n",
    "actual_sid = 'culo'\n",
    "session_ids = test_df['session_id'].values\n",
    "for sid in session_ids:\n",
    "    if sid != actual_sid:\n",
    "        actual_sid = sid\n",
    "        count+=1\n",
    "    qid_test.append(count)\n",
    "np_qid_test = np.array(qid_test)\n",
    "print(np_qid_test)\n",
    "\n",
    "X_test,Y_test= test_df.iloc[:, 4:], test_df['label']\n",
    "X_test_norm = scaler.fit_transform(X_test)\n",
    "Y_test_norm = Y_test.values\n",
    "#dummy_label = np.zeros(len(X_test),dtype=np.int)\n",
    "\n",
    "dump_svmlight_file(X_test_norm, Y_test_norm, './test.txt', query_id=np_qid_test, zero_based=False)\n",
    "np.save('./target_indices', target_indeces_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-05-01 18:02'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
