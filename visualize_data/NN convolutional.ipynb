{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "pd.options.display.max_columns = None\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Conv1D\n",
    "from keras import regularizers\n",
    "from keras.metrics import top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_metric(y_true, y_pred):\n",
    "    mrr = 0\n",
    "    current_percentage = 0\n",
    "    for i in range(1, 26, 1):\n",
    "        if i == 1:\n",
    "            mrr = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "            current_percentage = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "        else:\n",
    "            t = metrics.top_k_categorical_accuracy(y_true, y_pred, k=i)\n",
    "            mrr += (t - current_percentage) * (1 / i)\n",
    "            current_percentage = t\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_features(df, submission_mode=False):\n",
    "    # get the rows where the action is 'clickout item'\n",
    "    if submission_mode:\n",
    "        clickout_rows_df = df[(df['action_type'] == 'clickout item') & df['reference'].isnull()]\n",
    "    else:\n",
    "        clickout_rows_df = df[df['action_type'] == 'clickout item']\n",
    "\n",
    "    if len(clickout_rows_df) > 0:\n",
    "\n",
    "        # features\n",
    "        features = {\n",
    "            # impressions features\n",
    "            'times_impression_appeared': [],\n",
    "            'time_elapsed_from_last_time_impression_appeared': [],\n",
    "            'steps_from_last_time_impression_appeared': [],\n",
    "            'kind_action_reference_appeared': [],\n",
    "            'impression_position': [],\n",
    "            'label': [],\n",
    "            'price': [],\n",
    "            'price_position': [],\n",
    "\n",
    "            'delta_position': [],\n",
    "\n",
    "            # session features\n",
    "            'session_length': [],\n",
    "            'session_steps': [],\n",
    "            'time_from_last_action': [],\n",
    "            'reference_position_last_action': [],\n",
    "\n",
    "            'index': []}\n",
    "\n",
    "        clk = clickout_rows_df.tail(1)\n",
    "\n",
    "        head_index = df.head(1).index\n",
    "\n",
    "        # considering only the past!\n",
    "        # mantain of the df only the actions before the last clickout\n",
    "        df = df.loc[head_index.values[0]:clk.index.values[0] - 1]\n",
    "\n",
    "        if len(df) > 0:\n",
    "            session_length = clk['timestamp'].values[0] - df.head(1)['timestamp'].values[0]\n",
    "            time_from_last_action = clk['timestamp'].values[0] - df.tail(1)['timestamp'].values[0]\n",
    "            if df.tail(1)['reference'].values[0].isdigit():\n",
    "                last_ref = int(df.tail(1)['reference'])\n",
    "            else:\n",
    "                last_ref = 0\n",
    "        else:\n",
    "            session_length = -0.5\n",
    "            time_from_last_action = -0.5\n",
    "            last_ref = -0.5\n",
    "        session_steps = clk['step'].values[0]\n",
    "\n",
    "        # get the impression\n",
    "        impr = list(map(int, clk['impressions'].values[0].split('|')))\n",
    "\n",
    "        if last_ref in impr:\n",
    "            reference_position_last_action = impr.index(last_ref)\n",
    "        else:\n",
    "            reference_position_last_action = -0.5\n",
    "\n",
    "        prices = list(map(int, clk['prices'].values[0].split('|')))\n",
    "        sorted_prices = prices.copy()\n",
    "        sorted_prices.sort()\n",
    "\n",
    "        references = df['reference'].values\n",
    "\n",
    "        count = 0\n",
    "        for i in impr:\n",
    "            if reference_position_last_action >= 0:\n",
    "                delta_pos = count - reference_position_last_action\n",
    "            else:\n",
    "                delta_pos = count\n",
    "            indices = np.where(references == str(i))[0]\n",
    "\n",
    "            features['index'].append(clk.index[0])\n",
    "            features['impression_position'].append(count + 1)\n",
    "            features['price'].append(prices[count])\n",
    "            features['price_position'].append(sorted_prices.index(prices[count]))\n",
    "            if len(indices) > 0:\n",
    "                row_reference = df.head(indices[-1] + 1).tail(1)\n",
    "                features['steps_from_last_time_impression_appeared'].append(len(df) - indices[-1])\n",
    "                features['time_elapsed_from_last_time_impression_appeared'].append(\n",
    "                    int(clk['timestamp'].values[0] - row_reference['timestamp'].values[0]))\n",
    "                features['kind_action_reference_appeared'].append(row_reference['action_type'].values[0])\n",
    "            else:\n",
    "                features['steps_from_last_time_impression_appeared'].append(-0.5)\n",
    "                features['time_elapsed_from_last_time_impression_appeared'].append(-0.5)\n",
    "                features['kind_action_reference_appeared'].append('no_action')\n",
    "            features['times_impression_appeared'].append(len(indices))\n",
    "            features['delta_position'].append(delta_pos)\n",
    "            features['session_length'].append(session_length)\n",
    "            features['session_steps'].append(session_steps)\n",
    "            features['time_from_last_action'].append(time_from_last_action)\n",
    "            features['reference_position_last_action'].append(reference_position_last_action)\n",
    "\n",
    "            if submission_mode:\n",
    "                features['label'].append(0)\n",
    "            else:\n",
    "                if int(clk['reference'].values[0]) == i:\n",
    "                    features['label'].append(1)\n",
    "                else:\n",
    "                    features['label'].append(0)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        # zero padd the impressions with 0 feature values\n",
    "        missing_impr_count = 25 - len(impr)\n",
    "        if missing_impr_count > 0:\n",
    "            for k in features.keys():\n",
    "                if k == 'label':\n",
    "                    features[k].extend(np.zeros(missing_impr_count))\n",
    "                elif k == 'delta_position':\n",
    "                    features[k].extend(np.ones(missing_impr_count) * 25)\n",
    "                else:\n",
    "                    features[k].extend(np.ones(missing_impr_count) * -1)\n",
    "        return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE FEATURES DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features from TRAIN...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf58a253539741dc858e2391a5adabb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting features from TEST...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0e27edda2849588449251f4bb1f835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11448), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = data.train_df('small', 'no_cluster')\n",
    "test_df = data.test_df('small', 'no_cluster')\n",
    "\n",
    "print('extracting features from TRAIN...')\n",
    "train_features_dataframe = train_df.groupby(['user_id', 'session_id']).progress_apply(_extract_features)\n",
    "\n",
    "print('extracting features from TEST...')\n",
    "test_features_dataframe = test_df.groupby(['user_id', 'session_id']).progress_apply(_extract_features, submission_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling...\n",
      "shuffling...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f34558001547179c128c8e8ae0029c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41654), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, Y = train_features_dataframe.iloc[:, [0, 1, 2, 4, 6, 7, 8]], train_features_dataframe.iloc[:, 5]\n",
    "X_session_features = train_features_dataframe.iloc[:, [9, 10, 11, 12]]\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "print('scaling...')\n",
    "# normalize the values\n",
    "X_session_features_norm = scaler1.fit_transform(X_session_features)\n",
    "X_norm = scaler2.fit_transform(X)\n",
    "Y_norm = Y.values\n",
    "\n",
    "# removing duplicates from session featureS\n",
    "X_session_features = []\n",
    "for i in range(0, X_session_features_norm.shape[0], 25):\n",
    "    X_session_features.append(X_session_features_norm[i])\n",
    "X_session_features = np.array(X_session_features)\n",
    "\n",
    "# shuffle the data\n",
    "print('shuffling...')\n",
    "X_norm_shuffled = []\n",
    "Y_norm_shuffled = []\n",
    "for i in tqdm(range(0, X_norm.shape[0], 25)):\n",
    "    x, y = shuffle(X_norm[i:i + 25], Y_norm[i:i + 25])\n",
    "    X_norm_shuffled.append(x)\n",
    "    Y_norm_shuffled.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41654, 25, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_norm_shuffled).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41654, 25)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_norm_shuffled).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test data to be saved\n",
    "data_train = np.array(X_norm_shuffled)\n",
    "labels = np.array(Y_norm_shuffled)\n",
    "\n",
    "# add the session features to the samples\n",
    "#data_train = np.concatenate((data_train, X_session_features), axis=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(data_train, labels, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33323, 25, 7)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-1fc1c5cff1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(a, new_shape)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0mNa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m     \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mNa\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "np.resize(X_train, (-1, X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((33323, 25, 7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_29_input to have 4 dimensions, but got array with shape (33323, 25, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-a181d9591472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n\u001b[1;32m      3\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        shuffle=False)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/recsys/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_29_input to have 4 dimensions, but got array with shape (33323, 25, 7)"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n",
    "                       epochs=1000,\n",
    "                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(25,(25,1), input_shape=(25,7,1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "\n",
    "    #model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "\n",
    "    \n",
    "    model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[metrics.categorical_accuracy, mrr_metric])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
