{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:07:19.528097Z",
     "start_time": "2019-06-12T17:07:19.519312Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:07:23.399549Z",
     "start_time": "2019-06-12T17:07:19.815358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "from utils.dataset import DatasetScoresClassification #, SequenceDatasetForClassification\n",
    "from recommenders.recurrent.RNNClassificationRecommender import RNNClassificationRecommender\n",
    "#model = RNNClassificationRecommender(dataset, (6,168), 'gru', 2, 64, 2)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:07:23.410807Z",
     "start_time": "2019-06-12T17:07:23.402314Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = DatasetScoresClassification(f'dataset/preprocessed/cluster_recurrent/small/dataset_classification_p6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:07:23.441379Z",
     "start_time": "2019-06-12T17:07:23.422842Z"
    }
   },
   "outputs": [],
   "source": [
    "class KFoldScorer(object):\n",
    "    \"\"\"\n",
    "    Get the scores for the dataset by fitting each model in K-fold (except one) and\n",
    "    computing the scores for the left-out fold.\n",
    "    The underlying model should implement the following methods:\n",
    "    - fit_cv(x, y, x_val, y_val, **params)\n",
    "    - get_scores_cv(x)      : must return a dataframe with columns [ user_id | session_id | item_id | score ]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_class, init_params, k):\n",
    "        #assert hasattr(model, 'fit_cv') and hasattr(model, 'get_scores_cv'), \\\n",
    "        #    'Model must implement methods: fit_cv, get_scores_cv'\n",
    "        self.model_class = model_class\n",
    "        self.init_params = init_params\n",
    "        self.k = k\n",
    "        self.scores = []\n",
    "        \n",
    "    # train a single model on a fold\n",
    "    def _fit_model(self, x, y, x_val, y_val, fit_params, pool_id=0):\n",
    "        # print(x_val.shape)\n",
    "        # print(x_val[:,:,0][:,5])\n",
    "        # print(x_val[:,:,0][:,5].shape)\n",
    "        # print()\n",
    "        # return pool_id\n",
    "        print(f'start {pool_id}')\n",
    "        model = self.model_class(**self.init_params)\n",
    "        model.fit_cv(x, y, x_val, y_val, **fit_params)\n",
    "        print(f'fit end {pool_id}')\n",
    "        return model.get_scores_cv(x_val)\n",
    "\n",
    "    def fit_predict(self, dataset, fit_params={}, n_jobs=None, \n",
    "                    index_columns=[0], save_folder='scores/'):\n",
    "        \"\"\" Fit and compute the scores for each fold \"\"\"\n",
    "        assert hasattr(dataset, 'load_Xtrain') and hasattr(dataset, 'load_Ytrain') and hasattr(dataset, 'load_Xtest'), \\\n",
    "            'Dataset must implement methods: load_Xtrain, load_Ytrain, load_Xtest'\n",
    "        \n",
    "        X_train, Y_train, X_test = dataset.load_Xtrain()[:5], dataset.load_Ytrain()[:5], dataset.load_Xtest()[:5]\n",
    "\n",
    "        \n",
    "        # kfold\n",
    "        kf = KFold(n_splits=self.k)\n",
    "        \n",
    "        # fit in each fold\n",
    "        self.scores = Parallel(backend='multiprocessing', n_jobs=n_jobs)(delayed(self._fit_model)\n",
    "                                (X_train[train_indices], Y_train[train_indices], \n",
    "                                    X_train[test_indices], Y_train[test_indices], fit_params, idx)\n",
    "                                for idx, (train_indices,test_indices) in enumerate(kf.split(X_train)) )\n",
    "        \n",
    "        # fit in all the train and get scores for test\n",
    "        # model = copy.deepcopy(self.model)\n",
    "        # model.fit_cv(X_train, Y_train, None, None, **fit_params)\n",
    "        # scores_test = model.get_scores_cv(X_test)\n",
    "        # self.scores.append( scores_test )\n",
    "        \n",
    "        # check_folder(save_folder)\n",
    "        self.scores = pd.concat(self.scores)\n",
    "        return self.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:08:23.848142Z",
     "start_time": "2019-06-12T17:07:23.444533Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (37664, 6, 169)\n",
      "Y_train: (37664, 25)\n",
      "X_test: (9246, 6, 169)\n",
      "start 0\n",
      "start 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 6, 64)             44736     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1625      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 75,289\n",
      "Trainable params: 75,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "\n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 6, 64)             44736     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1625      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 75,289\n",
      "Trainable params: 75,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Train on 3 samples, validate on 2 samples\n",
      "Epoch 1/1\n",
      "Train on 2 samples, validate on 3 samples\n",
      "Epoch 1/1\n",
      "3/3 [==============================] - 6s 2s/step - loss: 7.3488 - acc: 0.0000e+00 - mrr: 0.1395 - val_loss: 2.9531 - val_acc: 0.5000 - val_mrr: 0.5417\n",
      "fit end 1\n",
      "2/2 [==============================] - 6s 3s/step - loss: 3.0226 - acc: 0.5000 - mrr: 0.5312 - val_loss: 2.7262 - val_acc: 0.6667 - val_mrr: 0.7778\n",
      "fit end 0\n",
      "caching df_full...\n",
      "caching df_full...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "/Users/federico/miniconda3/envs/recsys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "init_params = {\n",
    "    'dataset': dataset,\n",
    "    'input_shape': (6,168),\n",
    "    'cell_type': 'gru',\n",
    "    'num_recurrent_layers': 2,\n",
    "    'num_recurrent_units': 64,\n",
    "    'num_dense_layers': 2\n",
    "}\n",
    "fit_params = {'epochs': 1, 'early_stopping_patience': 4}\n",
    "\n",
    "kfscorer = KFoldScorer(model_class=RNNClassificationRecommender, init_params=init_params, k=2)\n",
    "\n",
    "_ = kfscorer.fit_predict(dataset, fit_params=fit_params, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:08:23.871988Z",
     "start_time": "2019-06-12T17:08:23.856772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kfscorer.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T17:08:34.136240Z",
     "start_time": "2019-06-12T17:08:34.053757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>2632452</td>\n",
       "      <td>0.082701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>5747484</td>\n",
       "      <td>0.049080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>110985</td>\n",
       "      <td>0.050279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>84220</td>\n",
       "      <td>0.031571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>3752262</td>\n",
       "      <td>0.019891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>85103</td>\n",
       "      <td>0.038115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>85285</td>\n",
       "      <td>0.040473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>1905271</td>\n",
       "      <td>0.030329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>82038</td>\n",
       "      <td>0.048797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>85306</td>\n",
       "      <td>0.051958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>88731</td>\n",
       "      <td>0.049668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>88755</td>\n",
       "      <td>0.027061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>84480</td>\n",
       "      <td>0.035757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>107312</td>\n",
       "      <td>0.048784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>83985</td>\n",
       "      <td>0.046690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>150905</td>\n",
       "      <td>0.034793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>88728</td>\n",
       "      <td>0.046656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>84397</td>\n",
       "      <td>0.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>85349</td>\n",
       "      <td>0.026240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>2808390</td>\n",
       "      <td>0.046220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>3754092</td>\n",
       "      <td>0.027474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>82506</td>\n",
       "      <td>0.028723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>2770354</td>\n",
       "      <td>0.035625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>150898</td>\n",
       "      <td>0.029258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778.0</th>\n",
       "      <td>0004IOZI7CKF</td>\n",
       "      <td>0146f7cb014ba</td>\n",
       "      <td>107267</td>\n",
       "      <td>0.047359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464545.0</th>\n",
       "      <td>0008B0X0HC39</td>\n",
       "      <td>1b703eda68d85</td>\n",
       "      <td>2762974</td>\n",
       "      <td>0.074379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697007.0</th>\n",
       "      <td>000ZN9219G41</td>\n",
       "      <td>1086064207e4f</td>\n",
       "      <td>149015</td>\n",
       "      <td>0.075033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697007.0</th>\n",
       "      <td>000ZN9219G41</td>\n",
       "      <td>1086064207e4f</td>\n",
       "      <td>1077638</td>\n",
       "      <td>0.051316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697007.0</th>\n",
       "      <td>000ZN9219G41</td>\n",
       "      <td>1086064207e4f</td>\n",
       "      <td>34819</td>\n",
       "      <td>0.054977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697007.0</th>\n",
       "      <td>000ZN9219G41</td>\n",
       "      <td>1086064207e4f</td>\n",
       "      <td>4384770</td>\n",
       "      <td>0.033818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>13435</td>\n",
       "      <td>0.022984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>231736</td>\n",
       "      <td>0.034243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>1231946</td>\n",
       "      <td>0.034849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>149255</td>\n",
       "      <td>0.031167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>341666</td>\n",
       "      <td>0.048428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>14082</td>\n",
       "      <td>0.045346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>5005660</td>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>341226</td>\n",
       "      <td>0.028019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>556686</td>\n",
       "      <td>0.036778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>6473688</td>\n",
       "      <td>0.047211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>883697</td>\n",
       "      <td>0.046731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>565196</td>\n",
       "      <td>0.037539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>923601</td>\n",
       "      <td>0.037758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>4124684</td>\n",
       "      <td>0.030685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>14088</td>\n",
       "      <td>0.025221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>99932</td>\n",
       "      <td>0.044821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>13458</td>\n",
       "      <td>0.033913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>99710</td>\n",
       "      <td>0.031285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>100023</td>\n",
       "      <td>0.030554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>5849416</td>\n",
       "      <td>0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884528.0</th>\n",
       "      <td>001OCXQ9PXET</td>\n",
       "      <td>362dc2be48010</td>\n",
       "      <td>13856</td>\n",
       "      <td>0.051057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>3366614</td>\n",
       "      <td>0.094478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>2670592</td>\n",
       "      <td>0.050848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>6625742</td>\n",
       "      <td>0.074646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>2881004</td>\n",
       "      <td>0.035327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>5708270</td>\n",
       "      <td>0.023592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>8415608</td>\n",
       "      <td>0.037509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>6779662</td>\n",
       "      <td>0.028905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>1873675</td>\n",
       "      <td>0.025265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725484.0</th>\n",
       "      <td>001TEVEVUEBE</td>\n",
       "      <td>394f5ad9aa596</td>\n",
       "      <td>2631204</td>\n",
       "      <td>0.052225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id     session_id  item_id     score\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  2632452  0.082701\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  5747484  0.049080\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba   110985  0.050279\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    84220  0.031571\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  3752262  0.019891\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    85103  0.038115\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    85285  0.040473\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  1905271  0.030329\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    82038  0.048797\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    85306  0.051958\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    88731  0.049668\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    88755  0.027061\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    84480  0.035757\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba   107312  0.048784\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    83985  0.046690\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba   150905  0.034793\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    88728  0.046656\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    84397  0.026501\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    85349  0.026240\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  2808390  0.046220\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  3754092  0.027474\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba    82506  0.028723\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba  2770354  0.035625\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba   150898  0.029258\n",
       "27778.0   0004IOZI7CKF  0146f7cb014ba   107267  0.047359\n",
       "464545.0  0008B0X0HC39  1b703eda68d85  2762974  0.074379\n",
       "697007.0  000ZN9219G41  1086064207e4f   149015  0.075033\n",
       "697007.0  000ZN9219G41  1086064207e4f  1077638  0.051316\n",
       "697007.0  000ZN9219G41  1086064207e4f    34819  0.054977\n",
       "697007.0  000ZN9219G41  1086064207e4f  4384770  0.033818\n",
       "...                ...            ...      ...       ...\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    13435  0.022984\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   231736  0.034243\n",
       "884528.0  001OCXQ9PXET  362dc2be48010  1231946  0.034849\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   149255  0.031167\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   341666  0.048428\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    14082  0.045346\n",
       "884528.0  001OCXQ9PXET  362dc2be48010  5005660  0.046353\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   341226  0.028019\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   556686  0.036778\n",
       "884528.0  001OCXQ9PXET  362dc2be48010  6473688  0.047211\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   883697  0.046731\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   565196  0.037539\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   923601  0.037758\n",
       "884528.0  001OCXQ9PXET  362dc2be48010  4124684  0.030685\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    14088  0.025221\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    99932  0.044821\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    13458  0.033913\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    99710  0.031285\n",
       "884528.0  001OCXQ9PXET  362dc2be48010   100023  0.030554\n",
       "884528.0  001OCXQ9PXET  362dc2be48010  5849416  0.028758\n",
       "884528.0  001OCXQ9PXET  362dc2be48010    13856  0.051057\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  3366614  0.094478\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  2670592  0.050848\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  6625742  0.074646\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  2881004  0.035327\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  5708270  0.023592\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  8415608  0.037509\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  6779662  0.028905\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  1873675  0.025265\n",
       "725484.0  001TEVEVUEBE  394f5ad9aa596  2631204  0.052225\n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = kfscorer.scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
